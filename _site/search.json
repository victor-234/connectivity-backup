[
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Backup Repo for Connectivity",
    "section": "",
    "text": "Backup Repo for Connectivity"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Connectivity Analyses",
    "section": "",
    "text": "We analyzed 1,447 annual reports of EURO Stoxx 600 firms from 2018 to 2022.\nWe then manually classified different sections of the reports:\n\nFinancial Statements and Notes\nAuditor’s Report\n\nFinally, we searched for different climate-related keywords:\n\n\n\n['ghg', 'co2', 'carbon', 'climat', 'emission', 'regulatory risk', 'physical risk', 'transition risk']\n\n\n\n\n\n\n\nSample selectionDescriptives\n\n\nWe distributed the EURO Stoxx 600 firms to student assistants to extract information on the structure of annual reports. So far, this resulted in the following documents sample:\n\nafter removing not readable pdfs (which is probably to sracping problems that can be fixed manually),\npdfs where no text was scanned, and\npdfs with too little words(documents where the average clean text characters are less than 1,500 in a document).\n\n\n\n\n\n\n\n\n\nTable 1: Sample selection documents\n\n\n\nless\nresulting\n\n\n\n\ndownloaded pdfs\n\n1447\n\n\n1. not readable\n-271\n1176\n\n\nthereof &lt;0.5MB:\n(271)\n\n\n\n2. zero text scanned\n-37\n1139\n\n\n3. chars/page &lt; 1,500\n-151\n988\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Document descriptives"
  },
  {
    "objectID": "index.html#method",
    "href": "index.html#method",
    "title": "Connectivity Analyses",
    "section": "",
    "text": "We analyzed 1,447 annual reports of EURO Stoxx 600 firms from 2018 to 2022.\nWe then manually classified different sections of the reports:\n\nFinancial Statements and Notes\nAuditor’s Report\n\nFinally, we searched for different climate-related keywords:\n\n\n\n['ghg', 'co2', 'carbon', 'climat', 'emission', 'regulatory risk', 'physical risk', 'transition risk']"
  },
  {
    "objectID": "index.html#documents",
    "href": "index.html#documents",
    "title": "Connectivity Analyses",
    "section": "",
    "text": "Sample selectionDescriptives\n\n\nWe distributed the EURO Stoxx 600 firms to student assistants to extract information on the structure of annual reports. So far, this resulted in the following documents sample:\n\nafter removing not readable pdfs (which is probably to sracping problems that can be fixed manually),\npdfs where no text was scanned, and\npdfs with too little words(documents where the average clean text characters are less than 1,500 in a document).\n\n\n\n\n\n\n\n\n\nTable 1: Sample selection documents\n\n\n\nless\nresulting\n\n\n\n\ndownloaded pdfs\n\n1447\n\n\n1. not readable\n-271\n1176\n\n\nthereof &lt;0.5MB:\n(271)\n\n\n\n2. zero text scanned\n-37\n1139\n\n\n3. chars/page &lt; 1,500\n-151\n988\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Document descriptives"
  },
  {
    "objectID": "index.html#keywords-over-time-1",
    "href": "index.html#keywords-over-time-1",
    "title": "Connectivity Analyses",
    "section": "Keywords over time (1)",
    "text": "Keywords over time (1)\n\nFS+Notes and AuditFS+Notes and Audit (no hits at all)By keyword\n\n\n\n\n\n\n\n\nFigure 2: Development of average hits\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: Percentage of documents w/o a hit\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Development of average hits by keyword"
  },
  {
    "objectID": "index.html#keywords-over-time-2",
    "href": "index.html#keywords-over-time-2",
    "title": "Connectivity Analyses",
    "section": "Keywords over time (2)",
    "text": "Keywords over time (2)\n\nFS+Notes and AuditFS+Notes and AuditFS+Notes and Audit (per Page)Full ARFull AR (per Page)\n\n\n\n\n\n\n\n\nFigure 5: Development of average hits\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: Development of average hits\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Development of hits per page\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Development of average hits\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: Development of hits per page"
  },
  {
    "objectID": "index.html#climate-alignment",
    "href": "index.html#climate-alignment",
    "title": "Connectivity Analyses",
    "section": "Climate alignment",
    "text": "Climate alignment\n\nBy ETS participationBy MSCI Climate Exposure ScoreBy MSCI Climate Exposure Score QuartilesBy MSCI Climate Exposure Score Quartiles over time\n\n\n\n\n\n\n\n\nFigure 10: Alignment measured by ETS participation\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: Alignment measured by MSCI Climate Exposure Score\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 12: Alignment measured by MSCI Climate Exposure Score Quartiles\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 13: Alignment over time measured by MSCI Climate Exposure Score Quartiles"
  },
  {
    "objectID": "index.html#climate-connectivity",
    "href": "index.html#climate-connectivity",
    "title": "Connectivity Analyses",
    "section": "Climate connectivity",
    "text": "Climate connectivity\n\nBy MSCI Emission Disclosure ScoresBy MSCI Emission Disclosure Scores by keywordBy Keyword Hits outside of FS and AuditBy SRN ESRS Readiness\n\n\n\n\n\n\n\n\nFigure 14: SustRep measured by MSCI Climate Emission Disclosure Score\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 15: SustRep measured by MSCI Climate Emission Disclosure Score by keyword\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 16: SustRep measured by Keyword Hits outside of FS and Audit\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 17: SustRep measured by SRN ESRS Readiness"
  },
  {
    "objectID": "index.html#relative-location-of-keywords-in-fsnotes",
    "href": "index.html#relative-location-of-keywords-in-fsnotes",
    "title": "Connectivity Analyses",
    "section": "Relative location of keywords in FS+Notes",
    "text": "Relative location of keywords in FS+Notes\nThis graph shows the relative location (0%: first page, 100%: last page) in the F/S + Notes section.\n\n\n\n\n\n\nFigure 18: Relative location"
  },
  {
    "objectID": "index.html#keyword-ranking",
    "href": "index.html#keyword-ranking",
    "title": "Connectivity Analyses",
    "section": "Keyword ranking",
    "text": "Keyword ranking\n\nRankingIn FS+Notes and AuditFull AR\n\n\n\n\n\n\n\n\nFigure 19: Keyword ranking\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 20: Keyword ranking by section\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 21: Keyword ranking by section"
  },
  {
    "objectID": "output-analyses.html",
    "href": "output-analyses.html",
    "title": "Technical stuff",
    "section": "",
    "text": "# ---\n# title: \"Connectivity Analyses\"\n# author: [\"Maximilian A. Müller\", \"Gaizka Ormazabal\", \"Thorsten Sellhorn\", \"Victor Wagner\"]\n# institute: [\"University of Cologne\", \"IESE\", \"LMU Munich School of Management\", \"LMU Munich School of Management\"]\n# number-sections: true\n\n# toc: true\n# format:\n#     html:\n#         toc: true\n# jupyter: python3\n# fig-width: 0.7\n# ---\n# echo: false\n# output: asis\n\n# # pdf:\n# #         geometry:\n# #             - paper=a4paper\n# #         fig-pos: 'h'\n\n# beamer:\n#         aspectratio: 169\n#         header-includes: |\n#             \\setbeamertemplate{navigation symbols}{}\n#             \\setbeamertemplate{footline}[page number]"
  },
  {
    "objectID": "output-analyses.html#getting-started",
    "href": "output-analyses.html#getting-started",
    "title": "Technical stuff",
    "section": "Getting started",
    "text": "Getting started\n\nimports\nSRN data\n(check which firms and documents are needed and which are already here); Currently, we base our analyses on the documents that have already been manually coded (bottom-up); in the future, however, we do it top-down based on Euro Stoxx 600\nread in document data\n\nread in manually coded documents\ncheck which have to be downloaded (b/c they are not here) and update\ncheck which have to be extracted (b/c it hasn’t been done) and update\nprepare for later analysis and merge with other data\n\n\n\nimport sys, os, json, re\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\n\n# path to Dropbox directory with 'pdf', 'pdf-decrypt', 'docs_clean.json' and 'raw_texts.json'\nBASE_PATH = \"/Users/victor.wagner/Dropbox/_Connectivity-Data\"\n# BASE_PATH = \"/Users/victorwagner/Library/CloudStorage/Dropbox/_Connectivity-Data\"\n\n\nAPI_PATH  = \"https://api.sustainabilityreportingnavigator.com/api\"\n\ncompanies = pd.read_json(f'{API_PATH}/companies')\ndocuments = pd.read_json(f'{API_PATH}/documents')\nindices   = pd.read_json(f'{API_PATH}/indices')\n\n\nes600 = companies[['1cc738c1-e6b1-4f2b-8bec-2d963118de59' in ind for ind in companies.indices]]\n\n# es600 = es600[['id', 'name', 'isin', 'country', 'sector']].merge(\n#     documents.query('type == \"AR\" & year in [2018, 2019, 2020, 2021, 2022]')[['id', 'year', 'type', 'company_id']], \n#     left_on='id', right_on='company_id',\n#     suffixes=('_company', '_document')\n# )\n\n\n# set(es600.name).difference(set(manual_collections_all.name_comp))\n\n\nRead in manually collected start/end pages\n\nfrom scripts.mergeManualCollections import mergeManualCollections\nmanual_collections_all = mergeManualCollections([\n    '../data/connectivity-manual_collection - lmu_cologne.csv',\n    '../data/connectivity-manual_collection-iese - main.csv',\n    '../data/connectivity-manual_collection-iese - second_round.csv',\n    '../data/connectivity-manual_collection-muhammad - lmu_only.csv',\n    '../data/connectivity-manual_collection-parth - lmu_only.csv'\n])\n\nmanual_collections = manual_collections_all.dropna(subset=['fs_begin', 'fs_end', 'audit_begin', 'audit_end'], how='any')\n\nprint('We have', len(manual_collections), 'manually coded documents, of which', \n      len(set(manual_collections.index).difference(set([x[:-4] for x in os.listdir(BASE_PATH + \"/pdf/\")]))),\n      'are not downloaded.') \n\nif len([x[:-4] for x in os.listdir(BASE_PATH + \"/pdf/\")]) &gt; len(manual_collections.index): \n    print('There are even', len(set([x[:-4] for x in os.listdir(BASE_PATH + \"/pdf/\")]).difference(set(manual_collections.index))),\n      'documents too much.')\n\nWe have 1448 manually coded documents, of which 0 are not downloaded.\nThere are even 21 documents too much.\n\n\n\n\nSample Balance Checks\n\nworldscope_msci = pd.read_csv('../data/worldscope_msci_carbon.csv')\n\nDtypeWarning: Columns (199,340) have mixed types. Specify dtype option on import or set low_memory=False.\n  worldscope_msci = pd.read_csv('../data/worldscope_msci_carbon.csv')\n\n\n\nes600a = es600.merge(\n    worldscope_msci.query('year == 2022').drop_duplicates('id'),\n    on=\"id\",\n    suffixes=(\"_comp\", \"_other\"),\n    indicator=True\n)\n\n\nsample    = es600a[es600a.id.isin(list(set(manual_collections.company_id)))]\nall_es600 = es600a[es600a.id.isin(list(set(manual_collections_all.company_id)))]\n\n\nfrom scripts.doBalanceChecks import balanceCheckMultiple\nsampleCheck2 = pd.DataFrame(\n    columns=['Sample', 'Full Euro STOXX 600', 'Difference', 'p-val']\n)\n\nprint(\n    balanceCheckMultiple(\n        [\n            {'name': 'Assets (bn$)',     'test': 'ttest',     'attrs': ['ITEM7230', 1000000000]},\n            {'name': 'Sales (bn$)',       'test': 'ttest',     'attrs': ['ITEM7240', 1000000000]},\n            {'name': 'Employees (,000)',  'test': 'ttest',     'attrs': ['ITEM7011', 1000]},\n            {'name': 'MSCI Emiss. Score',       'test': 'ttest',     'attrs': ['mcarbon_emissions_score', 1]},\n            {'name': 'MSCI Emiss. Mgmt. Score', 'test': 'ttest',     'attrs': ['mcarbon_emissions_score', 1]},\n            {'name': '% GER',             'test': 'chisquare', 'attrs': ['country', 'Germany']},\n            {'name': '% GBR',             'test': 'chisquare', 'attrs': ['country', 'United Kingdom']},\n            {'name': '% FRA',             'test': 'chisquare', 'attrs': ['country', 'France']},\n        ], \n        outDF = sampleCheck2,\n        sample = sample,\n        all_firms = all_es600\n).to_markdown()\n)\n\n|                   |   Sample |   Full Euro STOXX 600 | Difference   | p-val   |\n|:------------------|---------:|----------------------:|:-------------|:--------|\n| Assets (bn$)      |    79.04 |                 78.47 | 0.57         | 0.97    |\n| Sales (bn$)       |    19.53 |                 18.36 | 1.17         | 0.59    |\n| Employees (,000)  |    42.6  |                 40.02 | 2.57         | 0.58    |\n| MSCI Emiss. Score |     9.11 |                  9.14 | -0.03        | 0.71    |\n| % GER             |     0.2  |                  0.12 | 0.08         | 0.8     |\n| % GBR             |     0.25 |                  0.23 | 0.01         | 0.97    |\n| n                 |   286    |                544    | -            | -       |\n\n\n\nUse the following with caution, this will download, extract and clean all documents if they are not stored locally.\n\n\n\nUpdate pdfs if not all are downloaded yet\n\nfrom scripts.downloadPdfs import downloadPdfs\ndoc_status = downloadPdfs(\n    BASE_PATH,\n    zip(manual_collections['href_doc'],\n        manual_collections.index)\n)\nprint('There were', sum([x == 'downloaded' for x in doc_status]), 'new downloads,', \n      sum([x == 'no download' for x in doc_status]), 'documents could not be downloaded.')\n\nThere were 0 new downloads, 0 documents could not be downloaded.\n\n\n\ntoo_small_docs = [doc for doc in os.listdir(BASE_PATH + \"/pdf/\") if os.path.getsize((BASE_PATH+'/pdf/'+doc)) &lt; 500000]\nprint('There are', len(too_small_docs), 'documents that are smaller than 0.5 MB (indicating corruption).')\n\n# if len(too_small_docs) &gt; 0:\n#     manual_collections_all.loc[[x[:-4] for x in too_small_docs]].to_csv('corrupted_docs.csv')\n#     print('A csv-file with a list of corrupted docs has been saved. Please download the docs manually.')\n\nThere are 271 documents that are smaller than 0.5 MB (indicating corruption).\n\n\n\n\nExtract text from pdfs if not done so yet\n\nraw_texts_old = pd.read_json(f\"{BASE_PATH}/pdf/../raw_texts.json\")\nprint('We already have raw text for', len(raw_texts_old.query('status == \"fine\"')), 'documents, decrypting and reading',\n     len(manual_collections)-len(raw_texts_old.query('status == \"fine\"')), 'documents now.')\n\nfrom scripts.readTextFromPdf import readTextFromPdf\nraw_texts_new, doc_status_new = [], []\nraw_texts_new, doc_status_new = map(\n    list, \n    zip(*[readTextFromPdf(BASE_PATH, doc_id) for doc_id in manual_collections.index])\n)\nraw_texts_newDict = {doc_id: (r,s) for doc_id,r,s in zip(manual_collections.index, raw_texts_new, doc_status_new)}\n\nWe already have raw text for 1185 documents, decrypting and reading 263 documents now.\n\n\n\nfrom scripts.updateRawTexts import updateRawTexts\nraw_texts_final = updateRawTexts(raw_texts_old, raw_texts_newDict)\nraw_texts_final.to_json(f\"{BASE_PATH}/pdf/../raw_texts.json\")\n\nprint('There are', sum([x == 'problem_decrypting' for x in raw_texts_final.status]), 'documents with decryption problems', \n     'and', sum([x == 'problem_opening' for x in raw_texts_final.status]), 'documents that could not be read.')\nprint('This leaves us with a readable sample of', sum([x == 'fine' for x in raw_texts_final.status]), 'documents.')\n\nThere are 260 documents with decryption problems and 0 documents that could not be read.\nThis leaves us with a readable sample of 1185 documents.\n\n\n\n\nClean text if not done so yet\n\ndocs_cleaned_old = pd.read_json(f\"{BASE_PATH}/docs_clean.json\")\nprint('There is already clean data for', len(docs_cleaned_old.query('status == \"fine\"')), 'documents, cleaning',\n     len(raw_texts_final.query('status == \"fine\"'))-len(docs_cleaned_old.query('status == \"fine\"')), 'documents.')\n\nfrom scripts.updateAndCleanText import updateAndCleanText\ndocs_cleaned_new = updateAndCleanText(docs_cleaned_old, raw_texts_final)\ndocs_cleaned_new.to_json(f\"{BASE_PATH}/pdf/../docs_clean.json\")\n\nThere is already clean data for 1177 documents, cleaning 8 documents.\n\n\n\ndel raw_texts_final, raw_texts_new, raw_texts_newDict, raw_texts_old\ndel docs_cleaned_old\n\n\n\nMerge other data to documents\n\n# docs_cleaned_new.drop(columns=['clean_text_full'], inplace=True)\n\n# docs = docs_cleaned_new.merge(\n#     documents[['id', 'company_id', 'year']], \n#     left_index=True, right_on='id'\n# ).merge(\n#     companies[['id', 'name', 'isin', 'country', 'sector']], \n#     left_on='company_id', right_on='id',\n#     suffixes=('', '_company')\n# ).set_index(\n#     'id', drop=True\n# ).drop(\n#     'id_company', axis=1\n# )\n\n\n# This is better as it preserves 'new' documents found by RA's where no \n# document_id is in the SRN database\n\ndocs = pd.DataFrame(\n    columns=list(docs_cleaned_new.columns) + ['document_id', 'year', 'company_id', 'name', 'isin', 'country', 'sector']\n)\n\nfor doc_id, doc in docs_cleaned_new.iterrows():\n    if '_' not in doc_id:\n        company_id = documents[documents.id == doc_id]['company_id'].values[0]\n        year       = documents[documents.id == doc_id]['year'].values[0]\n        \n    else:\n        company_id = doc_id[:36]\n        year       = int(doc_id[-4:])\n        \n    docs.loc[len(docs)] = [\n        doc[0], doc[1], doc[2], doc[3], doc[4], doc[5], doc[6], doc[7], doc[8],\n        doc_id,\n        year,\n        company_id,\n        companies[companies.id == company_id]['name'].values[0],\n        companies[companies.id == company_id]['isin'].values[0],\n        companies[companies.id == company_id]['country'].values[0],\n        companies[companies.id == company_id]['sector'].values[0]\n    ]\n\ndocs.set_index('document_id', inplace=True)\n\n\n\nMerge manually coded section data\n\ndocs = docs.merge(\n    manual_collections[['mda_begin', 'mda_end', 'fs_begin', 'fs_end', 'audit_begin', 'audit_end']], \n    left_index=True, right_index=True\n)\n\n\n# docs = docs.reset_index(\n# ).merge(\n#     docs.groupby(\n#         ['company_id']).size().reset_index(\n#     ).rename(\n#         columns={0: 'company_years_avlbl'}), on='company_id'\n# ).set_index('index')\n\n\n# Drop obvious outlier\ndocs.drop(docs[(docs['isin'] == 'ES0130670112') & (docs['year'] == 2020)].index, inplace=True)"
  },
  {
    "objectID": "output-analyses.html#sec-doc-sample",
    "href": "output-analyses.html#sec-doc-sample",
    "title": "Technical stuff",
    "section": "Document sample selection",
    "text": "Document sample selection\nWe distributed the EURO Stoxx 600 firms to student assistants to extract information on the structure of annual reports. So far, this resulted in the following documents sample: 1. after removing not readable pdfs, 2. pdfs where no text was scanned, and 3. pdfs with too little words (documents where the average clean text characters are less than 1,500 in a document).\n\ndocs0 = docs.query('status == \"fine\"')\ndocs1 = docs0.query('clean_text_len &gt; 0')\ndocs2 = docs1.query('avgCleanTextPerPage &gt; 1500')\n\nTpdfSample = pd.DataFrame(columns=['less', 'resulting'])\n\nTpdfSample.loc['downloaded pdfs']       = ['',                             len(docs)]\nTpdfSample.loc['1. not readable']       = ['-'+str(len(docs) -len(docs0)), len(docs0)]\nTpdfSample.loc['thereof &lt;0.5MB:']       = ['('+str(len(too_small_docs))+')', '']\nTpdfSample.loc['2. zero text scanned']  = ['-'+str(len(docs0)-len(docs1)), len(docs1)]\nTpdfSample.loc['3. chars/page &lt; 1,500'] = ['-'+str(len(docs1)-len(docs2)), len(docs2)]\n\n#print(TpdfSample.to_markdown(index=False))\n#print('\\nThis leaves us with', len(docs2['company_id'].unique()), 'unique firms.')\n\n\nTpdfSample\n\n\n\n\n\n\nTable 1: Sample selection documents\n\n\n\nless\nresulting\n\n\n\n\ndownloaded pdfs\n\n1447\n\n\n1. not readable\n-271\n1176\n\n\nthereof &lt;0.5MB:\n(271)\n\n\n\n2. zero text scanned\n-37\n1139\n\n\n3. chars/page &lt; 1,500\n-151\n988"
  },
  {
    "objectID": "output-analyses.html#keyword-search",
    "href": "output-analyses.html#keyword-search",
    "title": "Technical stuff",
    "section": "Keyword search",
    "text": "Keyword search\n\n#from scripts.findSections import findSections\npd.options.mode.chained_assignment = None  # default='warn'\n\ndocsa = findSections(docs2)\n\n\nsearch_patterns = ['ghg', 'co2', 'carbon', 'climat', 'emission', 'regulatory risk', 'physical risk', 'transition risk']\nprint(search_patterns)\n\n['ghg', 'co2', 'carbon', 'climat', 'emission', 'regulatory risk', 'physical risk', 'transition risk']\n\n\n\nlim = 200\n\ndef searchText(doc, search_patterns):\n    matches = []\n    for section in ['fs_text', 'audit_text', 'other_text']:\n        for pat in search_patterns:\n            for page, text in doc[section+'_dict'].items():\n                for hit in re.finditer(pat, text):\n                    matches.append({\n                        'pattern': pat,\n                        'section': section[:-5],\n                        'snippet': text[hit.start()-lim : hit.start()+len(pat)+lim],\n                        'page'   : page\n                    })\n                \n    return matches\n\ndocsa['hits'] = [pd.DataFrame(searchText(doc, search_patterns)) for _, doc in docsa.iterrows()]\n\n\nlim = 200\n\ndef searchText(doc, search_patterns):\n    matches = []\n    for section in ['fs_text', 'audit_text', 'other_text']:\n        for pat in search_patterns:\n            for page, text in doc[section+'_dict'].items():\n                for hit in re.finditer(pat, text):\n                    matches.append({\n                        'pattern': pat,\n                        'section': section[:-5],\n                        'snippet': text[hit.start()-lim : hit.start()+len(pat)+lim],\n                        'page'   : page\n                    })\n                \n    return matches\n\ndocsa['finhits'] = [pd.DataFrame(searchText(doc, ['asset', 'revenue', 'sales', 'employee'])) for _, doc in docsa.iterrows()]\n\n\ndocsa['total_hits']    = [len(doc.hits) for _, doc in docsa.iterrows()]\ndocsa['avg_hits']      = docsa['total_hits'] / docsa['n_pages']\ndocsa['total_finhits'] = [len(doc.finhits) for _, doc in docsa.iterrows()]\ndocsa['avg_finhits']   = docsa['total_finhits'] / docsa['n_pages']\n\n\n# snippets = pd.DataFrame(columns=['document_id', 'isin', 'year', 'pattern', 'section', 'snippet'])\n\n# for idx, doc in docsa.iterrows():\n#     for _, hit in doc.hits.iterrows():\n#         snippets.loc[len(snippets)] = [idx, doc['isin'], doc['year'], hit['pattern'], hit['section'], hit['snippet']]\n    \n# snippets.info()\n# snippets.to_csv('snippets.csv', index=False)"
  },
  {
    "objectID": "output-analyses.html#keywords-over-time",
    "href": "output-analyses.html#keywords-over-time",
    "title": "Technical stuff",
    "section": "Keywords over time",
    "text": "Keywords over time\n\ndata = docsa.copy()\n\nfor sec in sections:\n    data[sec+'_hits'] = [len(list(filter(lambda hit: hit['section'] == sec, searchText(doc, search_patterns)))) for _, doc in docsa.iterrows()]\n\ndata['total_hits'] = [len(searchText(doc, search_patterns)) for _, doc in docsa.iterrows()]\n\n\navg_hits_perSec_perYear = [[np.mean(data.query('year == @year')[sec+'_hits']) for year in years] for sec in sections]\nmed_hits_perSec_perYear = [[np.median(data.query('year == @year')[sec+'_hits']) for year in years] for sec in sections]\navg_hitsPerPage_perSec_perYear = [[np.mean(data.query('year == @year')[sec+'_hits']/data.query('year == @year')['n_pages']) for year in years] for sec in sections]\n\n\nfs_hits_avg_yrs =    [np.mean(data.query('year == @year')['fs_hits'])    for year in years]\naudit_hits_avg_yrs = [np.mean(data.query('year == @year')['audit_hits']) for year in years]\n# mda_hits_avg_yrs =   [np.mean(data.query('year == @year')['mda_hits'])   for year in years]\nother_hits_avg_yrs = [np.mean(data.query('year == @year')['other_hits']) for year in years]\n\nfs_hits_med_yrs =    [np.median(data.query('year == @year')['fs_hits'])    for year in years]\naudit_hits_med_yrs = [np.median(data.query('year == @year')['audit_hits']) for year in years]\n# mda_hits_med_yrs =   [np.median(data.query('year == @year')['mda_hits'])   for year in years]\nother_hits_med_yrs = [np.median(data.query('year == @year')['other_hits']) for year in years]\n\n\nfig, ax1 = plt.subplots()\n\nax1.plot(years, med_hits_perSec_perYear[0], 'o-', color='#ff1f5b', label='fs+notes')\nax1.plot(years, med_hits_perSec_perYear[1], 'o-', color='#009ade', label='audit')\n\n# for year, n in zip(years, range(len(years))):\n#     ax1.plot(\n#         (year, year), \n#         (med_hits_perSec_perYear[0][n]+fs_hits_q3[n], \n#          med_hits_perSec_perYear[0][n]-fs_hits_q1[n]), \n#         '_-', color='#ff1f5b', alpha=0.5\n#     )\n#     ax1.plot(\n#         (year, year), \n#         (med_hits_perSec_perYear[1][n]+audit_hits_q3[n], \n#          med_hits_perSec_perYear[1][n]-audit_hits_q1[n]), \n#         '_-', color='#009ade', alpha=0.5\n#     )\n\nax1.set_ylabel('median hits per section')\n\ndocsPerYear = [len(data.query('year == @year')) for year in years]\nax2 = ax1.twinx()\nax2.bar(x=years, height=docsPerYear, color='gray', alpha=0.2)\nax2.set_ylim([0,600])\nax2.tick_params(axis='y')\nax2.set_ylabel('#docs')\n\nplt.table([[round(y, 2) for y in x] for x in med_hits_perSec_perYear+[docsPerYear]],\n         rowLabels=['fs+notes', 'audit', 'other', '#docs'],\n         rowColours=['#ff1f5b', '#009ade', '#ffffff', 'lightgray'],\n         colLabels=years, loc='bottom', cellLoc='right', edges='horizontal', bbox=[0, -0.4, 1, 0.4])\n\nax1.set_xticks([])\nax2.set_xticks([])\n#ax1.set_title(f'n={len(data)} reports with {sum(data[\"total_hits\"])} total keyword hits with IQR')\nax1.legend()#ncol=4, bbox_to_anchor=(0.75,-0.1))\n\n#fig.savefig('figures/fig202309271823.png', dpi=400, bbox_inches='tight')\nplt.show()\n\n\n\n\n\nfig, ax1 = plt.subplots()\n\nax1.plot(years, avg_hits_perSec_perYear[0], 'o-', color='#ff1f5b', label='fs+notes')\nax1.plot(years, avg_hits_perSec_perYear[1], 'o-', color='#009ade', label='audit')\n\nax1.set_ylabel('average hits per section')\n\ndocsPerYear = [len(data.query('year == @year')) for year in years]\nax2 = ax1.twinx()\nax2.bar(x=years, height=docsPerYear, color='gray', alpha=0.2)\nax2.set_ylim([0,600])\nax2.tick_params(axis='y')\nax2.set_ylabel('#docs')\n\nplt.table([[round(y, 2) for y in x] for x in avg_hits_perSec_perYear+[docsPerYear]],\n         rowLabels=['fs+notes', 'audit', 'other', '#docs'],\n         rowColours=['#ff1f5b', '#009ade', '#ffffff', 'lightgray'],\n         colLabels=years, loc='bottom', cellLoc='right', edges='horizontal', bbox=[0, -0.4, 1, 0.4])\n\nax1.set_xticks([])\nax2.set_xticks([])\n#ax1.set_title(f'n={len(data)} reports with {sum(data[\"total_hits\"])} total keyword hits with IQR')\nax1.legend()#ncol=4, bbox_to_anchor=(0.75,-0.1))\n\n#fig.savefig('figures/fig202309271823.png', dpi=400, bbox_inches='tight')\nplt.show()\n\n\n\n\n\nfs_hits_byY = [data.query('year == @year')['fs_hits'].values for year in years]\nfs_hits_ci  = [stats.t.interval(0.95, len(hits_byY)-1, loc=hits_byY.mean(), scale=stats.sem(hits_byY)) for hits_byY in fs_hits_byY]\n\naudit_hits_byY = [data.query('year == @year')['audit_hits'].values for year in years]\naudit_hits_ci  = [stats.t.interval(0.95, len(hits_byY)-1, loc=hits_byY.mean(), scale=stats.sem(hits_byY)) for hits_byY in audit_hits_byY]\n\n\nfig, ax1 = plt.subplots()\n\nax1.plot(years, avg_hits_perSec_perYear[0], 'o-', color='#ff1f5b', label='fs+notes')\nax1.plot(years, avg_hits_perSec_perYear[1], 'o-', color='#009ade', label='audit')\n\nfor year, n in zip(years, range(len(years))):\n    ax1.plot(\n        (year, year), \n        (avg_hits_perSec_perYear[0][n]+(fs_hits_ci[n][1]-fs_hits_ci[n][0])/2, \n         avg_hits_perSec_perYear[0][n]-(fs_hits_ci[n][1]-fs_hits_ci[n][0])/2), \n        '_-', color='#ff1f5b', alpha=0.5)\n    ax1.plot(\n        (year, year), \n        (avg_hits_perSec_perYear[1][n]+(audit_hits_ci[n][1]-audit_hits_ci[n][0])/2, \n         avg_hits_perSec_perYear[1][n]-(audit_hits_ci[n][1]-audit_hits_ci[n][0])/2), \n        '_-', color='#009ade', alpha=0.5)\n\nax1.set_ylabel('average hits per section')\n\ndocsPerYear = [len(data.query('year == @year')) for year in years]\nax2 = ax1.twinx()\nax2.bar(x=years, height=docsPerYear, color='gray', alpha=0.2)\nax2.set_ylim([0,600])\nax2.tick_params(axis='y')\nax2.set_ylabel('#docs')\n\nplt.table([[round(y, 2) for y in x] for x in avg_hits_perSec_perYear+[docsPerYear]],\n         rowLabels=['fs+notes', 'audit', 'other', '#docs'],\n         rowColours=['#ff1f5b', '#009ade', '#ffffff', 'lightgray'],\n         colLabels=years, loc='bottom', cellLoc='right', edges='horizontal', bbox=[0, -0.4, 1, 0.4])\n\nax1.set_xticks([])\nax2.set_xticks([])\n#ax1.set_title(f'n={len(data)} reports with {sum(data[\"total_hits\"])} total keyword hits with IQR')\nax1.legend()#ncol=4, bbox_to_anchor=(0.75,-0.1))\n\n#fig.savefig('figures/fig202309271823.png', dpi=400, bbox_inches='tight')\nplt.show()\n\n\n\n\n\nfs_hits_byY_win = [stats.mstats.winsorize(data.query('year == @year')['fs_hits'].values, limits=[0,0.05]) for year in years]\nfs_hits_byY_avg = [np.mean(x) for x in fs_hits_byY_win]\nfs_hits_win_ci  = [stats.t.interval(0.95, len(hits_byY)-1, loc=hits_byY.mean(), scale=stats.sem(hits_byY)) for hits_byY in fs_hits_byY_win]\n\naudit_hits_byY_win = [stats.mstats.winsorize(data.query('year == @year')['audit_hits'].values, limits=[0,0.05]) for year in years]\naudit_hits_byY_avg = [np.mean(x) for x in audit_hits_byY_win]\naudit_hits_win_ci  = [stats.t.interval(0.95, len(hits_byY)-1, loc=hits_byY.mean(), scale=stats.sem(hits_byY)) for hits_byY in audit_hits_byY_win]\n\nC:\\Users\\victor.wagner\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2351: RuntimeWarning: invalid value encountered in multiply\n  lower_bound = _a * scale + loc\nC:\\Users\\victor.wagner\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:2352: RuntimeWarning: invalid value encountered in multiply\n  upper_bound = _b * scale + loc\n\n\n\nmpl.rcParams['figure.dpi'] = 100\nfig, ax1 = plt.subplots()\n\ndocsPerYear = [len(data.query('year == @year')) for year in years]\nnoHitDocsPerYear = [len(data.query('year == @year and fs_hits == 0')) for year in years]\nax2 = ax1.twinx()\nax2.bar(x=years, height=noHitDocsPerYear, color='gray', alpha=0.1, label='docs w/o fs hits')\nax2.bar(x=years, height=np.array(docsPerYear)-np.array(noHitDocsPerYear), color='gray', alpha=0.2, bottom=noHitDocsPerYear, label='docs w/ fs hits')\n\nax2.set_ylim([0,600])\nax2.tick_params(axis='y')\nax2.set_ylabel('#docs')\n\nax1.plot(years, fs_hits_byY_avg, 'o-', color='#ff1f5b', label='fs+notes')\nax1.plot(years, audit_hits_byY_avg, 'o-', color='#009ade', label='audit')\n\nfor year, n in zip(years, range(len(years))):\n    ax1.plot(\n        (year, year), \n        (fs_hits_byY_avg[n]+(fs_hits_win_ci[n][1]-fs_hits_win_ci[n][0])/2, \n         fs_hits_byY_avg[n]-(fs_hits_win_ci[n][1]-fs_hits_win_ci[n][0])/2), \n        '_-', color='#ff1f5b', alpha=0.5)\n    ax1.plot(\n        (year, year), \n        (audit_hits_byY_avg[n]+(audit_hits_win_ci[n][1]-audit_hits_win_ci[n][0])/2, \n         audit_hits_byY_avg[n]-(audit_hits_win_ci[n][1]-audit_hits_win_ci[n][0])/2), \n        '_-', color='#009ade', alpha=0.5)\n\nax1.set_ylabel('average hits per section')\n\nplt.table([[round(y, 2) for y in x] for x in avg_hits_perSec_perYear+[docsPerYear]],\n         rowLabels=['fs+notes', 'audit', 'other', '#docs'],\n         rowColours=['#ff1f5b', '#009ade', '#ffffff', 'lightgray'],\n         colLabels=years, loc='bottom', cellLoc='right', edges='horizontal', bbox=[0, -0.4, 1, 0.4])\n\nax1.set_xticks([])\nax2.set_xticks([])\n# ax1.set_title(f'n={len(data)} reports with {sum([sum(x) for x in fs_hits_byY])} total hits in fs+notes\\n with CI (winsorized)')\nfig.legend(bbox_to_anchor=(0.37,0.87), fontsize='small')\n\n#fig.savefig('figures/fig202309271823.png', dpi=400, bbox_inches='tight')\nplt.show()\n\n\n\n\nFigure 1: Development of average hits\n\n\n\n\n\nfrom scipy.interpolate import make_interp_spline\nsplined_fs    = make_interp_spline(years, fs_hits_byY_avg)\nsplined_audit = make_interp_spline(years, audit_hits_byY_avg)\n\nyears_spl = np.linspace(min(years), max(years), 500)\ny_fs      = splined_fs(years_spl)\ny_audit   = splined_audit(years_spl)\n\n\nfig, ax1 = plt.subplots()\n\nax1.plot(years_spl, y_fs, '-', color='#ff1f5b', label='fs+notes')\nax1.plot(years_spl, y_audit, '-', color='#009ade', label='audit')\n\n# for year, n in zip(years, range(len(years))):\n#     ax1.plot(\n#         (year, year), \n#         (avg_hits_perSec_perYear[0][n]+fs_hits_ci[n][0], \n#          avg_hits_perSec_perYear[0][n]+fs_hits_ci[n][1]), \n#         '_-', color='#ff1f5b', alpha=0.5)\n#     ax1.plot(\n#         (year, year), \n#         (avg_hits_perSec_perYear[1][n]+audit_hits_ci[n], \n#          avg_hits_perSec_perYear[1][n]+audit_hits_ci[n]), \n#         '_-', color='#009ade', alpha=0.5)\n\nax1.set_ylabel('average hits per section')\n\ndocsPerYear = [len(data.query('year == @year')) for year in years]\nax2 = ax1.twinx()\nax2.bar(x=years, height=docsPerYear, color='gray', alpha=0.2)\nax2.set_ylim([0,600])\nax2.tick_params(axis='y')\nax2.set_ylabel('#docs')\n\nplt.table([[round(y, 2) for y in x] for x in avg_hits_perSec_perYear+[docsPerYear]],\n         rowLabels=['fs+notes', 'audit', 'other', '#docs'],\n         rowColours=['#ff1f5b', '#009ade', '#ffffff', 'lightgray'],\n         colLabels=years, loc='bottom', cellLoc='right', edges='horizontal', bbox=[0, -0.4, 1, 0.4])\n\nax1.set_xticks([])\nax2.set_xticks([])\n#ax1.set_title(f'n={len(data)} reports with {sum(data[\"total_hits\"])} total keyword hits with IQR')\nax1.legend()#ncol=4, bbox_to_anchor=(0.75,-0.1))\n\n#fig.savefig('figures/fig202309280927.png', dpi=400, bbox_inches='tight')\nplt.show()\n\n\n\n\nFigure 2: Development of average hits\n\n\n\n\n\nfig, ax1 = plt.subplots()\n\nax1.plot(years, avg_hits_perSec_perYear[0], 'o-', color='#ff1f5b', label='fs+notes')\nax1.plot(years, avg_hits_perSec_perYear[1], 'o-', color='#009ade', label='audit')\nax1.plot(years, avg_hits_perSec_perYear[2], 'o-', color='#ffc61e', label='other')\n\nax1.set_ylabel('average hits per section')\n\ndocsPerYear = [len(data.query('year == @year')) for year in years]\nax2 = ax1.twinx()\nax2.bar(x=years, height=docsPerYear, color='gray', alpha=0.2)\nax2.set_ylim([0,600])\nax2.tick_params(axis='y')\nax2.set_ylabel('#docs')\n\nplt.table([[round(y, 2) for y in x] for x in avg_hits_perSec_perYear+[docsPerYear]],\n         rowLabels=['fs+notes', 'audit', 'other', '#docs'],\n         rowColours=['#ff1f5b', '#009ade', '#ffc61e', 'lightgray'],\n         colLabels=years, loc='bottom', cellLoc='right', bbox=[0, -0.4, 1, 0.4])\n\nax1.set_xticks([])\nax2.set_xticks([])\n#ax1.set_title(f'n={len(data)} reports with {sum(data[\"total_hits\"])} total keyword hits')\nax1.legend()#ncol=4, bbox_to_anchor=(0.75,-0.1))\n\n#fig.savefig('figures/fig202309272029.png', dpi=400, bbox_inches='tight')\nplt.show()\n\n\n\n\nFigure 3: Development of average hits\n\n\n\n\n\nfig, ax1 = plt.subplots()\n\nax1.plot(years, avg_hitsPerPage_perSec_perYear[0], 'o-', color='#ff1f5b', label='fs+notes')\nax1.plot(years, avg_hitsPerPage_perSec_perYear[1], 'o-', color='#009ade', label='audit')\nax1.plot(years, avg_hitsPerPage_perSec_perYear[2], 'o-', color='#ffc61e', label='other')\n\nax1.set_ylabel('average hits per page by section')\n\ndocsPerYear = [len(data.query('year == @year')) for year in years]\nax2 = ax1.twinx()\nax2.bar(x=years, height=docsPerYear, color='gray', alpha=0.2)\nax2.set_ylim([0,600])\nax2.tick_params(axis='y')\nax2.set_ylabel('#docs')\n\nplt.table([[round(y, 2) for y in x] for x in avg_hitsPerPage_perSec_perYear+[docsPerYear]],\n         rowLabels=['fs+notes', 'audit', 'other', '#docs'],\n         rowColours=['#ff1f5b', '#009ade', '#ffc61e', 'lightgray'],\n         colLabels=years, loc='bottom', cellLoc='right', bbox=[0, -0.4, 1, 0.4])\n\nax1.set_xticks([])\nax2.set_xticks([])\n#ax1.set_title(f'n={len(data)} reports with {sum(data[\"total_hits\"])} total keyword hits')\nax1.legend()#ncol=4, bbox_to_anchor=(0.75,-0.1))\n\n#fig.savefig('figures/fig202309272029.png', dpi=400, bbox_inches='tight')\nplt.show()\n\n\n\n\nFigure 4: Development of hits per page\n\n\n\n\n\nfig, ax1 = plt.subplots()\n\nax1.plot(years, avg_hitsPerPage_perSec_perYear[0], 'o-', color='#ff1f5b', label='fs+notes')\nax1.plot(years, avg_hitsPerPage_perSec_perYear[1], 'o-', color='#009ade', label='audit')\n\nax1.set_ylabel('average hits per page by section')\n\ndocsPerYear = [len(data.query('year == @year')) for year in years]\nax2 = ax1.twinx()\nax2.bar(x=years, height=docsPerYear, color='gray', alpha=0.2)\nax2.set_ylim([0,600])\nax2.tick_params(axis='y')\nax2.set_ylabel('#docs')\n\nplt.table([[round(y, 2) for y in x] for x in avg_hitsPerPage_perSec_perYear+[docsPerYear]],\n         rowLabels=['fs+notes', 'audit', 'other', '#docs'],\n         rowColours=['#ff1f5b', '#009ade', '#ffc61e', 'lightgray'],\n         colLabels=years, loc='bottom', cellLoc='right', bbox=[0, -0.4, 1, 0.4])\n\nax1.set_xticks([])\nax2.set_xticks([])\n#ax1.set_title(f'n={len(data)} reports with {sum(data[\"total_hits\"])} total keyword hits')\nax1.legend()#ncol=4, bbox_to_anchor=(0.75,-0.1))\n\n#fig.savefig('figures/fig202309272029.png', dpi=400, bbox_inches='tight')\nplt.show()\n\n\n\n\nFigure 5: Development of hits per page"
  },
  {
    "objectID": "output-analyses.html#keyword-ranking",
    "href": "output-analyses.html#keyword-ranking",
    "title": "Technical stuff",
    "section": "Keyword ranking",
    "text": "Keyword ranking\n\ndata = docsa.copy()\n\nfor pat in search_patterns:\n    data[pat] = [len(list(filter(lambda hit: hit['pattern'] == pat, searchText(doc, search_patterns)))) for _, doc in docsa.iterrows()]\n    \ndata['total_hits'] = [len(searchText(doc, search_patterns)) for _, doc in docsa.iterrows()]\n\n\nfig, ax = plt.subplots()\n\nax.bar(search_patterns, [np.sum(data[pat].values) for pat in search_patterns], color='#a0b1ba', zorder=2)\n#ax.set_title(f'Distribution of hits per keyword (total hits={sum(data.total_hits)})')\nax.text(6.35,50500,f'n={sum(data.total_hits)}')\n\nplt.grid(axis='y', color='lightgray', zorder=0)\n\nplt.xticks(rotation=90)\nplt.show()\n#plt.savefig('figures/fig202309272100.png', dpi=400, bbox_inches='tight')\n\n\n\n\nFigure 6: Keyword ranking"
  },
  {
    "objectID": "output-analyses.html#keyword-ranking-by-section",
    "href": "output-analyses.html#keyword-ranking-by-section",
    "title": "Technical stuff",
    "section": "Keyword ranking by section",
    "text": "Keyword ranking by section\nThe difference b/w the total number of search hits is because from here, I included ghg and co2\n\nsections = ['fs', 'audit', 'other']\n\ntotals = {k:v for k,v in zip(\n    sections,\n    [[sum(len(list(filter(lambda hit: (hit['section'] == sec) & (hit['pattern'] == pat), searchText(doc, search_patterns))))\n          for _, doc in docsa.iterrows()) \n      for pat in search_patterns] \n     for sec in sections]\n)}\n\n\nfig, ax = plt.subplots()\n\nwidth = 0.2\nlabel_locs = np.arange(len(search_patterns))\nmultiplier = 0\n\nfor sec in list(totals.keys())[:2]:\n    offset = width * multiplier\n    ax.bar(label_locs+offset, totals[sec], width=width, label=sec, edgecolor='w')\n    #ax.bar_label(rects, padding=3)\n    multiplier += 1\n    \nax.set_xticks(label_locs+width)\nax.set_xticklabels(search_patterns)\nplt.xticks(rotation=90)\nax.legend()\n\nplt.show()\n# plt.savefig('figures/fig202309272158.png', dpi=400, bbox_inches='tight')\n\n\n\n\nFigure 7: Keyword ranking by section\n\n\n\n\n\nfig, ax = plt.subplots()\n\nwidth = 0.2\nlabel_locs = np.arange(len(search_patterns))\nmultiplier = 0\n\nfor sec, byKeyword in totals.items():\n    offset = width * multiplier\n    ax.bar(label_locs+offset, byKeyword, width=width, label=sec, edgecolor='w')\n    #ax.bar_label(rects, padding=3)\n    multiplier += 1\n    \nax.set_xticks(label_locs+width)\nax.set_xticklabels(search_patterns)\nplt.xticks(rotation=90)\nax.legend(loc='upper right')\n\nplt.show()\n# plt.savefig('figures/fig202309272147.png', dpi=400, bbox_inches='tight')\n\n\n\n\nFigure 8: Keyword ranking by section"
  },
  {
    "objectID": "output-analyses.html#heatmap-of-hits-in-the-document",
    "href": "output-analyses.html#heatmap-of-hits-in-the-document",
    "title": "Technical stuff",
    "section": "Heatmap of hits in the document",
    "text": "Heatmap of hits in the document\n\ndata1 = pd.DataFrame(columns=[\n    'document_id', 'company_id', 'year', 'fs_begin', 'fs_end', 'audit_begin', 'audit_end', \n    'pattern', 'section', 'page'\n])\n\nfor doc_id, doc in docsa.iterrows():\n    for _, hit in doc.hits.iterrows():\n        if (hit.section == 'fs') or (hit.section == 'audit'):\n            data1.loc[len(data1)] = [\n                doc_id, doc.company_id, doc.year, doc.fs_begin, doc.fs_end, doc.audit_begin, doc.audit_end,\n                hit.pattern, hit.section, hit.page\n            ]\n\n\ndata1_onlyFS    = data1.query('section == \"fs\"').drop(['audit_begin', 'audit_end', 'section'], axis=1)\ndata1_onlyaudit = data1.query('section == \"audit\"').drop(['fs_begin', 'fs_end', 'section'], axis=1)\n\n\ndata1_onlyFS_noMult = data1_onlyFS[[',' not in str(x) for x in data1_onlyFS['fs_begin']]]\ndata1_onlyaudit_noMult = data1_onlyaudit[[',' not in str(x) for x in data1_onlyaudit['audit_begin']]]\nprint('By restricting to no multi-start sections, we lose', \n      len(data1_onlyFS)-len(data1_onlyFS_noMult), 'snippets.\\n',\n      'Left:', len(data1_onlyFS_noMult))\n\nBy restricting to no multi-start sections, we lose 90 snippets.\n Left: 6327\n\n\n\ndata1_onlyFS_noMult['location'] = [int(snip['page']) / int(snip['fs_end']) for _,snip in data1_onlyFS_noMult.iterrows()]\ndata1_onlyaudit_noMult['location'] = [int(snip['page']) / int(snip['audit_end']) for _,snip in data1_onlyaudit_noMult.iterrows()]\n\n\nfig, ax = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(6,6))\n\ncustomprops = dict(linestyle='--', linewidth=1, color='gray')\n\n# ax.boxplot(data1_onlyFS_noMult['location'], showfliers=0, showmeans=1, meanline=1, showcaps=0, \n#            boxprops=customprops, whiskerprops=customprops, capprops=customprops, \n#            medianprops=dict(color='#ff1f5b'), meanprops=dict(linestyle=':', linewidth=1, color='gray'))\n\nfor n, year in enumerate([2018, 2020, 2022]):\n    sns.stripplot(data=data1_onlyFS_noMult.query('year == @year'), \n                  x='location', y='pattern', \n                  color=colors[n], alpha=0.4, size=2.5, ax=ax[n], order=search_patterns)\n    ax[n].grid(color='lightgray', axis='y', linestyle='dashed')\n    ax[n].set_ylabel('')\n    ax[n].set_title(year)\n    \n\nax[0].set_xlim([0,1])\nax[2].set_xlabel('')\n\nplt.show()\n\n\n\n\nFigure 9: Relative location"
  },
  {
    "objectID": "output-analyses.html#cross-sectional-splits",
    "href": "output-analyses.html#cross-sectional-splits",
    "title": "Technical stuff",
    "section": "Cross-sectional splits",
    "text": "Cross-sectional splits\nFirst, create a more lightweight data structure\n\ndocsl = docs.loc[docsa.index].copy()[['year', 'isin', 'company_id', 'country', 'sector', 'n_pages', 'clean_text_len']]\n\nfor sec in ['fs', 'audit', 'other']:\n    docsl[sec+'_hit'] = [len(list(filter(lambda hit: hit['section'] == sec, searchText(doc, search_patterns)))) for _, doc in docsa.iterrows()]\n    \n    for pat in search_patterns:\n        docsl[pat+'_'+sec+'_hit'] = [len(list(filter(lambda hit: (hit['pattern'] == pat) and (hit['section'] == sec), searchText(doc, search_patterns)))) for _, doc in docsa.iterrows()]\n\ndocsl_backup = docsl.copy()\n\n\nMerge other data\n\netsmatch = pd.read_stata(f'{BASE_PATH}/research_data/OrbisETSMatch.dta')\netsmatch['ets'] = True\n\n\ndocsl = docsl.reset_index(\n).merge(\n    etsmatch[['ISINnumber', 'ets']], \n    left_on='isin', right_on='ISINnumber', \n    how='outer', \n    indicator=True\n).query(\n    '_merge != \"right_only\"'\n).drop_duplicates(\n    ['isin', 'year'], keep='last'\n).drop(\n    '_merge', axis=1\n).set_index(\n    'document_id'\n)\n\ndocsl['ets'].fillna(False, inplace=True)\n\n\nworldscope_msci = pd.read_csv(f'{BASE_PATH}/research_data/worldscope_msci_carbon.csv')\n\nDtypeWarning: Columns (199,340) have mixed types. Specify dtype option on import or set low_memory=False.\n  worldscope_msci = pd.read_csv(f'{BASE_PATH}/research_data/worldscope_msci_carbon.csv')\n\n\n\ndocsl = docsl.reset_index(\n).merge(\n    worldscope_msci, \n    on=['isin', 'year'],\n    indicator=True\n).drop_duplicates(\n    ['isin', 'year'], keep='last'\n).query(\n    \"_merge != 'right_only'\"\n).drop(\n    '_merge', axis=1\n).set_index(\n    'document_id'\n)\n\n\nreadiness_2022 = pd.read_json(API_PATH+'/companies/readiness_summary_all?standard_family=esrs&year=2022&include_unverified=true')\nreadiness_2021 = pd.read_json(API_PATH+'/companies/readiness_summary_all?standard_family=esrs&year=2021&include_unverified=true')\nreadiness_2020 = pd.read_json(API_PATH+'/companies/readiness_summary_all?standard_family=esrs&year=2020&include_unverified=true')\n\nreadiness_2022['esrs_emissM'] = [pd.DataFrame(r).query('topic == \"GHG emissions (metrics)\"')['readiness_extended'].values[0] for r in readiness_2022.by_topic2]\nreadiness_2022['year'] = 2022\nreadiness_2021['esrs_emissM'] = [pd.DataFrame(r).query('topic == \"GHG emissions (metrics)\"')['readiness_extended'].values[0] for r in readiness_2021.by_topic2]\nreadiness_2021['year'] = 2021\nreadiness_2020['esrs_emissM'] = [pd.DataFrame(r).query('topic == \"GHG emissions (metrics)\"')['readiness_extended'].values[0] for r in readiness_2021.by_topic2]\nreadiness_2020['year'] = 2020\n\n\ndocsl = docsl.reset_index(\n).merge(\n    pd.concat(\n        [\n            readiness_2022[['company_id', 'year', 'esrs_emissM']],\n            readiness_2021[['company_id', 'year', 'esrs_emissM']],\n            readiness_2020[['company_id', 'year', 'esrs_emissM']],\n        ],\n        ignore_index=True\n    ),\n    how=\"outer\",\n    on=['company_id', 'year'],\n    indicator=True\n).query(\n    '_merge != \"right_only\"'\n).set_index(\n    'document_id'\n).drop(\n    '_merge', axis=1\n)\n\n\ndocsl.drop('7903d3ee-6e26-457d-84b8-b396958609b7', axis=0, inplace=True)\n\n\n\nDescriptives\n\nmpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=['#FF1F5B', '#00CD6C', '#009ADE', '#AF58BA', '#FFC61E', '#F28522', '#A0B1BA', '#A6761D', '#E9002D', '#FFAA00', '#00B000'])\nmpl.rcParams['axes.prop_cycle'] = mpl.cycler(color=['#4472c4ff', '#ed7d31ff', '#a5a5a5ff', '#ffc000ff', '#5b9bd5ff', '#70ad47ff', '#264478ff', '#9e480eff'])\n\n\nfig, ax = plt.subplots()\nax.plot(docsl.groupby('year')['fs_hit'].apply(lambda x: sum(x==0)/len(x)), 'o-', label='fs')\nax.plot(docsl.groupby('year')['audit_hit'].apply(lambda x: sum(x==0)/len(x)), 'o-', label='audit')\nax.grid(axis=\"y\")\nax.set_ylabel(\"No hits\")\nax.set_xticks(years)\nax.set_ylim([0,1])\nax.legend()\nplt.show()\n\n\n\n\nFigure 10: Percentage of documents w/o a hit\n\n\n\n\n\nfig, ax = plt.subplots()\nax.plot(docsl.groupby('year')['fs_hit'].mean(), 'o-', label='fs')\nax.plot(docsl.groupby('year')['audit_hit'].mean(), 'o-', label='audit')\nax.set_ylabel(\"Search hits in FS + Notes\")\nax.grid(axis=\"y\")\nax.legend()\nax.set_xticks(years)\nplt.show()\n\n\n\n\nFigure 11: Development of average hits\n\n\n\n\n\nfig, ax = plt.subplots()\n\nbottom = np.zeros(len(years))\nfor pat in ['climat', 'emission', 'carbon', 'co2', 'ghg', 'physical risk', 'transition risk', 'regulatory risk']:\n    means = docsl.groupby('year')[f'{pat}_fs_hit'].mean().values\n    ax.bar(years, means, width=0.5, label=pat, bottom=bottom)\n    bottom += means\n\nax.set_ylabel(\"Search hits in FS + Notes\")\nplt.legend(ncol=4, bbox_to_anchor=(1.1,-0.1))\nplt.show()\n\n\n\n\nFigure 12: Development of average hits by keyword\n\n\n\n\n\n\nAlignment\n\nfig, ax = plt.subplots()\n\nbottom = np.zeros(2)\nfor pat in ['climat', 'emission', 'carbon', 'co2', 'ghg', 'physical risk', 'transition risk', 'regulatory risk']:\n    means = docsl.groupby('ets')[f'{pat}_fs_hit'].mean().values\n    ax.bar(['No ETS', 'ETS'], means, width=0.8, label=pat, bottom=bottom)\n    bottom += means\n\nax.set_ylabel(\"Search hits in FS + Notes\")\nplt.legend(ncol=4, bbox_to_anchor=(1.1,-0.1))\nplt.show()\n\n\n\n\nFigure 13: Alignment measured by ETS participation\n\n\n\n\n\ndocsl['high_climRiskExp'] = [x &gt; np.nanmedian(docsl.mcarbon_emissions_exp_score) if ~np.isnan(x) else None for x in docsl.mcarbon_emissions_exp_score.values]\n\n\nfig, ax = plt.subplots()\n\nbottom = np.zeros(2)\nfor pat in ['climat', 'emission', 'carbon', 'co2', 'ghg', 'physical risk', 'transition risk', 'regulatory risk']:\n    means = docsl.groupby('high_climRiskExp')[f'{pat}_fs_hit'].mean().values\n    ax.bar(['Low climate risk', 'High climate risk'], means, width=0.8, label=pat, bottom=bottom)\n    bottom += means\n\nax.set_ylabel(\"Search hits in FS + Notes\")\nplt.legend(ncol=4, bbox_to_anchor=(1.1,-0.1))\nplt.show()\n\n\n\n\nFigure 14: Alignment measured by MSCI Climate Exposure Score\n\n\n\n\n\ndef sortIntoQuartile(value, array):\n    q1 = np.nanquantile(array, 0.25)\n    q2 = np.nanquantile(array, 0.50)\n    q3 = np.nanquantile(array, 0.75)\n    if ~np.isnan(value):\n        if value &gt; q3:\n            return 'q4'\n        elif value &gt; q2:\n            return 'q3'\n        elif value &gt; q1:\n            return 'q2'\n        else:\n            return 'q1'\n    else:\n        return None\n\n\ndocsl['quart_climRiskExp'] = [sortIntoQuartile(x, docsl.mcarbon_emissions_exp_score) for x in docsl.mcarbon_emissions_exp_score.values]\n\n\nfs_hits_perClimRiskQuart = [docsl.query('quart_climRiskExp == @q')['fs_hit'].values for q in ['q1', 'q2', 'q3', 'q4']]\nfs_hits_perClimRiskQuart_ci = [stats.t.interval(0.95, len(hits_byQ)-1, loc=hits_byQ.mean(), scale=stats.sem(hits_byQ)) for hits_byQ in fs_hits_perClimRiskQuart]\n\n\nfig, ax = plt.subplots()\n\nbottom = np.zeros(4)\nfor pat in ['climat', 'emission', 'carbon', 'co2', 'ghg', 'physical risk', 'transition risk', 'regulatory risk']:\n    means = docsl.groupby('quart_climRiskExp')[f'{pat}_fs_hit'].mean().values\n    ax.bar(['q1', 'q2', 'q3', 'q4'], means, width=0.8, label=pat, bottom=bottom)\n    bottom += means\n    \nfor n, q in enumerate(['q1', 'q2', 'q3', 'q4']):\n    ax.plot([q,q], \n            [\n                fs_hits_perClimRiskQuart_ci[n][0],\n                fs_hits_perClimRiskQuart_ci[n][1]\n            ], 'k_-', linewidth=0.75)\n\nax.set_ylabel(\"Search hits in FS + Notes\")\nax.set_xlabel(\"MSCI Exposure Score Quartile\")\nplt.legend(ncol=4, bbox_to_anchor=(1.1,-0.17))\nplt.show()\n\n\n\n\nFigure 15: Alignment measured by MSCI Climate Exposure Score Quartiles\n\n\n\n\n\nfig, ax = plt.subplots()\n\nfor q in ['q1', 'q2', 'q3', 'q4']:\n    ax.plot(years, docsl[docsl.quart_climRiskExp == q].groupby('year')['fs_hit'].mean().values, label=q)\n\nax.set_xticks(years)\nax.set_ylabel(\"Search hits in FS + Notes\")\nax.grid(axis='y')\nplt.legend(ncol=4, bbox_to_anchor=(0.85,-0.1))\nplt.show()\n\n\n\n\nFigure 16: Alignment over time measured by MSCI Climate Exposure Score Quartiles\n\n\n\n\n\nfig, ax = plt.subplots()\n\nfor q in ['q1', 'q2', 'q3', 'q4']:\n    ax.plot(years, docsl[docsl.quart_climRiskExp == q].groupby('year')['fs_hit'].apply(lambda x: sum(x==0)/len(x)), label=q)\n\nax.set_xticks(years)\nax.set_ylabel(\"Percentage of documents w/o hits\")\nax.set_ylim([0,1])\nax.grid(axis='y')\nplt.legend(ncol=4, bbox_to_anchor=(0.85,-0.1))\nplt.show()\n\n\n\n\n\n\nConnectivity\n\ndocsl['high_emissDiscl'] = [x &gt;= round(np.nanmedian(docsl.mcarbon_emissions_mgmt_score),2) if ~np.isnan(x) else np.NaN for x in docsl.mcarbon_emissions_mgmt_score]\n\n\nprint('n all docs\\t\\t', len(docsl))\nprint('docs above median\\t', len(docsl[docsl['high_emissDiscl'] == True]))\nprint('docs below median\\t', len(docsl[docsl['high_emissDiscl'] == False]))\nprint('docs w/ na\\t\\t', sum(docsl['high_emissDiscl'].isna()))\nprint('docs where score==median', sum([x == np.nanmedian(docsl['mcarbon_emissions_mgmt_score']) for x in docsl['mcarbon_emissions_mgmt_score']]))\nprint('332-222 = \\t\\t', 332-222)\n\nn all docs       985\ndocs above median    525\ndocs below median    382\ndocs w/ na       78\ndocs where score==median 138\n332-222 =        110\n\n\n\nfig, ax = plt.subplots()\n\nbottom = np.zeros(2)\nfor pat in ['climat', 'emission', 'carbon', 'co2', 'ghg', 'physical risk', 'transition risk', 'regulatory risk']:\n    means = docsl.groupby('high_emissDiscl')[f'{pat}_fs_hit'].mean().values\n    ax.bar(['Low Disclosure Scores', 'High Disclosure Scores'], means, width=0.8, label=pat, bottom=bottom)\n    bottom += means\n\nax.set_ylabel(\"Search hits in FS + Notes\")\nplt.legend(ncol=4, bbox_to_anchor=(1.1,-0.1))\nplt.show()\n\n\n\n\nFigure 17: SustRep measured by MSCI Climate Emission Disclosure Score\n\n\n\n\n\nfig, ax = plt.subplots()\n\npatterns = ['climat', 'emission', 'carbon', 'co2', 'ghg']\nlabelloc = np.arange(len(patterns))\nwidth = 0.3\nmultiplier = 0\n\nfor state, label in zip([False, True], ['Low Disclosure Scores', 'High Disclosure Scores']):\n    offset = width*multiplier\n    rects = ax.bar(labelloc+offset, \n                   [docsl[docsl.high_emissDiscl == state][f'{pat}_fs_hit'].mean() for pat in patterns], \n                   width=width, label=label, zorder=2)\n    multiplier += 1\n\nax.set_xticks(labelloc+width*0.5, patterns)\nax.set_ylabel(\"Search hits in FS + Notes\")\nax.grid(axis=\"y\")\nplt.legend(ncol=4, bbox_to_anchor=(0.95,-0.1))\nplt.show()\n\n\n\n\nFigure 18: SustRep measured by MSCI Climate Emission Disclosure Score by keyword\n\n\n\n\n\ndocsl['high_outsideHit'] = [x &gt;= docsl['other_hit'].quantile() for x in docsl.other_hit]\n\n\nfig, ax = plt.subplots()\n\nbottom = np.zeros(2)\nfor pat in ['climat', 'emission', 'carbon', 'co2', 'ghg', 'physical risk', 'transition risk', 'regulatory risk']:\n    means = docsl.groupby('high_outsideHit')[f'{pat}_fs_hit'].mean().values\n    ax.bar(['Low Outside Hits', 'High Outside Hits'], means, width=0.5, label=pat, bottom=bottom, zorder=2)\n    bottom += means\n\nax.set_ylabel(\"Search hits in FS + Notes\")\nax.grid(axis='y')\nplt.legend(ncol=4, bbox_to_anchor=(1.1,-0.1))\nplt.show()\n\n\n\n\nFigure 19: SustRep measured by Keyword Hits outside of FS and Audit\n\n\n\n\n\nfig, ax = plt.subplots()\n\nax.plot(docsl.other_hit, docsl.fs_hit, '.', alpha=0.4)\nax.set_ylabel('Search hits in FS + Notes')\nax.set_xlabel('Search hits outside of FS + Notes')\n#ax.grid(axis=\"y\")\nplt.show()\n\n\n\n\n\nfig, ax = plt.subplots()\n\nlabelloc = np.arange(2)\nwidth = 0.3\nmultiplier = 0\n\nfor state, label in zip([False, True], ['Low Outside Hits', 'High Outside Hits']):\n    offset = width*multiplier\n    rects = ax.bar(labelloc+offset, \n                   docsl[docsl.high_outsideHit == state].groupby('high_climRiskExp')[f'fs_hit'].mean(), \n                   width=width, label=label, zorder=2)\n    multiplier += 1\n\nax.set_xticks(labelloc+width*0.5, ['Low Climate Risk', 'High Climate Risk'])\nax.set_ylabel(\"Search hits in FS + Notes\")\nax.grid(axis=\"y\")\nplt.legend(ncol=2, bbox_to_anchor=(0.95,-0.1))\nplt.show()\n\n\n\n\n\nfig, ax = plt.subplots()\n\nlabelloc = np.arange(2)\nwidth = 0.3\nmultiplier = 0\n\nfor state, label in zip([False, True], ['Low Disclosure Scores', 'High Disclosure Scores']):\n    offset = width*multiplier\n    rects = ax.bar(labelloc+offset, \n                   docsl[docsl.high_emissDiscl == state].groupby('high_climRiskExp')[f'fs_hit'].mean(), \n                   width=width, label=label, zorder=2)\n    multiplier += 1\n\nax.set_xticks(labelloc+width*0.5, ['Low Climate Risk', 'High Climate Risk'])\nax.set_ylabel(\"Search hits in FS + Notes\")\nax.grid(axis=\"y\")\nplt.legend(ncol=2, bbox_to_anchor=(0.95,-0.1))\nplt.show()\n\n\n\n\n\ndocsl['high_SRN'] = [x &gt;= docsl['esrs_emissM'].quantile() if ~np.isnan(x) else None for x in docsl.esrs_emissM]\n\n\nfig, ax = plt.subplots()\n\nbottom = np.zeros(2)\nfor pat in ['climat', 'emission', 'carbon', 'co2', 'ghg', 'physical risk', 'transition risk', 'regulatory risk']:\n    means = docsl.groupby('high_SRN')[f'{pat}_fs_hit'].mean()\n    ax.bar(['Low SRN ESRS Readiness', 'High SRN ESRS Readiness'], means, width=0.5, label=pat, bottom=bottom, zorder=2)\n    bottom += means\n\nax.set_ylabel(\"Search hits in FS + Notes\")\nax.grid(axis='y')\nplt.legend(ncol=4, bbox_to_anchor=(1.10,-0.1))\nplt.show()\n\n\n\n\nFigure 20: SustRep measured by SRN ESRS Readiness\n\n\n\n\n\nfig, ax = plt.subplots()\n\nlabelloc = np.arange(2)\nwidth = 0.3\nmultiplier = 0\n\nfor state, label in zip([False, True], ['Low SRN Readiness', 'High SRN Readiness']):\n    offset = width*multiplier\n    rects = ax.bar(labelloc+offset, \n                   docsl[docsl.high_SRN == state].groupby('high_climRiskExp')[f'fs_hit'].mean(), \n                   width=width, label=label, zorder=2)\n    multiplier += 1\n\nax.set_xticks(labelloc+width*0.5, ['Low Climate Risk', 'High Climate Risk'])\nax.set_ylabel(\"Search hits in FS + Notes\")\nax.grid(axis=\"y\")\nplt.legend(ncol=2, bbox_to_anchor=(0.95,-0.1))\nplt.show()"
  },
  {
    "objectID": "output-analyses.html#document-descriptives",
    "href": "output-analyses.html#document-descriptives",
    "title": "Technical stuff",
    "section": "Document descriptives",
    "text": "Document descriptives\n\nfig, ax = plt.subplots(1,3, figsize=(12,3))\n\nax[0].hist(docsa['n_pages'], edgecolor=\"w\", bins=25, color='#a0b1ba')\nax[0].set_title(f'Panel A. Total page numbers')\n\nax[1].hist(docsa['clean_text_len'], edgecolor=\"w\", bins=25, color='#a0b1ba')\nax[1].set_title(f'Panel B. Clean text lengths')\n\nax[2].hist(docsa['avgCleanTextPerPage'], edgecolor=\"w\", bins=25, color='#a0b1ba')\nax[2].set_title(f'Panel C. Clean text lengths per page')\nax[2].text(x=8400, y=-20, s=f'Cropped at 1,500', ha='right')\n\nfig.suptitle(f\"n={len(docsa)} documents\", y=1.1)\nplt.show()\n#fig.savefig('figures/fig202309272049.png', dpi=400, bbox_inches='tight')\n\n\n\n\nFigure 21: Document descriptives\n\n\n\n\n\nimport nltk\n\n\nfrom nltk.tokenize import sent_tokenize, word_tokenize\n\n\nx = sent_tokenize(docsa.iloc[0]['fs_text'])\nx"
  }
]